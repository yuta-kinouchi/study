{"gpu": -1, "env": "SumoEnv2-v0", "arch": "FFSoftmax", "bound_mean": false, "seed": 37099, "outdir": "results", "steps": 36000, "eval_interval": 100000, "eval_n_runs": 100, "reward_scale_factor": 0.01, "standardize_advantages": false, "render": false, "lr": 0.0003, "weight_decay": 0.0, "demo": true, "load": "./network/ppo_v2", "logger_level": 20, "monitor": false, "update_interval": 2048, "batchsize": 64, "epochs": 10, "entropy_coef": 0.0}